[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Building Blocks",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\nLinear Algebra\nProbability"
  },
  {
    "objectID": "misc.html#calculus",
    "href": "misc.html#calculus",
    "title": "1  Miscellaneous",
    "section": "1.1 Calculus",
    "text": "1.1 Calculus\nEuler’s number \\(e\\) is defined in terms of a limit approaching infinity.\n\\[\ne = \\lim_{x \\to \\infty} \\bigg( 1 + \\frac{1}{x} \\bigg)^x \\approx 2.718282...\n\\]\nWe also call this a horizontal asymptote.\n\n\nCode\nfoo <- function(x) (1 + 1/x)^x\n\nggplot() + \n  xlim(-5, 50) +\n  coord_cartesian(ylim = c(0.5, 5)) +\n  labs(x = \"x\", y = \"f(x)\") +\n  geom_function(fun = foo,  n = 1e3) + \n  geom_hline(yintercept = exp(1), linetype = \"dashed\")\n\n\n\n\n\nNote that the limit is undefined as \\(x \\to 0\\).\n\n1.1.1 Derivatives\nLimit Definition\n\\[\n\\begin{align}\nf'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}, &&\\text{provided the limit exists}\n\\end{align}\n\\tag{1.1}\\]\nDerivatives are used to understand instantaneous rates of change, i.e., when \\(\\Delta x \\approx 0\\).\nThis formula is equivalent:\n\\[\nf^\\prime (a) = \\lim_{b \\to a} \\frac{f(b) - f(a)}{b-a}\n\\]\nFor example, the area of a growing square is \\(A(x) = x^2\\). How does \\(A(x)\\) change every time \\(x\\) changes? We have that, for any given value of \\(x\\), the rate of instantaneous change is given by:\n\\[\n\\begin{align}\nA^\\prime (x) = 2x && \\text{or} && \\frac{dA}{dx} = 2x\n\\end{align}\n\\]\nNote. When \\(\\Delta\\) is infinitely small we change notation to \\(d\\).\nIf we zoom in on any function at a given point \\(a\\), a tangent line at \\(a\\) will be given by the following formula:\n\\[\ny = f(a) + f^\\prime (a) (x-a)\n\\]\n\nlinear approximation of \\(f\\) near \\(x=a\\)\n\nCritical points\n\\(c\\) is a critical point for the smooth function \\(f\\) iff \\(f^\\prime(c) = 0\\).\nIn order to figure out if \\(c\\) is a local maximum or local minimum, we use the second derivative. The second derivative of \\(f\\) measures the rate of change of the first derivative. In a nutshell, we find critical points by solving \\(f^\\prime = 0\\). We then plug these values into \\(f^{\\prime\\prime}\\). If the result is positive, the critical point is a local minimum; if the result is negative, the critical point is a local maximum.\nThis procedure does not always work.\nNote. For higher order derivatives we use the \\(f^{(n)}(x)\\) notation, where \\(f^{(0)}(x) = f(x)\\). We can also use the symbol \\(\\frac{d^nf}{dx^n}\\) for this purpose.\nDerivative Rules:\nThe constant rule—i.e., constants can move into and out of derivatives.\n\\[\n\\frac{d}{dt} \\bigg[c f(t) \\bigg] = c \\frac{d}{dt} \\bigg[f(t)\\bigg] = c \\cdot f^\\prime (t)\n\\tag{1.2}\\]\nThe sum rule—i.e., the derivative of the sum is the sum of the derivatives.\n\\[\n\\frac{d}{dt}\\bigg[ f(t) + g(t) \\bigg] = f^\\prime (t) + g^\\prime (t)\n\\tag{1.3}\\]\nThe product rule.\n\\[\n\\frac{d}{dx} \\bigg[f(x) g(x) \\bigg] = f(x) g^\\prime (x) + g(x) f^\\prime(x)\n\\tag{1.4}\\]\nThe power rule.\n\\[\n\\frac{d}{dx} \\bigg[ x^n\\bigg] = n \\cdot x^{n-1}\n\\tag{1.5}\\]\nNote. All these rules make it possible to estimate the derivative of any polynomial of the form \\(c_nx^n + c_{n-1} x^{n-1} + \\dots + c_1\\).\nThe chain rule allows us to find derivatives of compositions.\n\\[\n\\frac{d}{dx} \\bigg[ (f \\circ g)(x) \\bigg] = f^\\prime (g(x)) \\cdot g^\\prime (x)\n\\tag{1.6}\\]\n\n\\[\n(f \\circ g)(x) = f(g(x))\n\\]\n\nWe can use Equation 1.5 and Equation 1.6 to figure out the following:\n\\[\n\\frac{d}{dx} \\bigg[ \\frac{1}{g(x)} \\bigg] = - \\frac{g^\\prime (x)}{g(x)^2}\n\\]\nUsing this with Equation 1.4, we can figure out the quotient rule:\n\\[\n\\frac{d}{dx} \\bigg[ \\frac{f(x)}{g(x)}\\bigg] = f^\\prime (x) \\Bigg( \\frac{1}{g(x)} \\Bigg) + f(x) \\Bigg(- \\frac{g^\\prime (x)}{g(x)^2} \\Bigg) = \\frac{f^\\prime (x) g(x) - f(x) g^\\prime (x)}{g(x)^2}\n\\tag{1.7}\\]\n\n\n1.1.2 Integrals\nWhat is the area \\(A(a, b)\\) below the graph \\(y = f(x) \\geq 0\\), above the \\(x\\)-axis, and between \\(x=a\\), and \\(x=b\\)? We can estimate \\(A(a, b)\\) with a sum, and then argue that the estimate becomes exact as the number of terms approximates \\(\\infty\\). This is called a Riemann sum.\n\\[\nA(a, b) = \\underbrace{\\int_a^b \\overbrace{f(x)}^{\\small \\text{integrand}} dx}_\\text{integral}\n\\]\nThe elongated \"s\" stands for \"sum,\" when the number of terms to be summed approaches infinity. The decorations on the \"s\" are called the lower and upper limits of integration.\nThe symbols \\(f(x) \\cdot dx\\) make it clear that the terms of a Riemann sum are the areas of rectangles:\n\\[\n\\begin{align}\n\\text{base: } (x_{n+1} - x_n), &&\\text{height: }f \\bigg( \\frac{x_n + x_{n+1}}{2} \\bigg)\n\\end{align}\n\\]\nFor example,\n\\[\n\\int_0^1 x^2 dx = \\frac{x^3}{3} \\Bigg|_0^1 = \\frac{1^3}{3} - \\frac{0^3}{3} = \\frac{1}{3}\n\\]\nrepresents the area shaded in pink in the following graph:\n\n\nCode\nggplot() + \n  xlim(-0.5, 1.5) + \n  geom_function(fun = \\(x) x^2) +\n  stat_function(geom = \"area\", fun = \\(x) x^2, xlim = c(0, 1), fill = \"pink\") + \n  labs(x = \"x\")\n\n\n\n\n\n\n\nCode\nintegrate(\\(x) x^2, lower = 0, upper = 1)\n\n\n0.3333333 with absolute error < 3.7e-15\n\n\nCode\nn <- 100\nx <- seq(0, 1, length.out = n)\n\nresult <- 0\nfor (i in 1:(n - 1)) {\n  result <- result + (x[i + 1] - x[i]) * ((x[i] + x[i + 1])/2)^2\n}\n\nresult\n\n\n[1] 0.3333248\n\n\n\n100 is much smaller than \\(\\infty\\)\n\nWe use the area under the curve in this graph to think about many things—e.g., displacement of an object with \\(x\\) as time and \\(y\\) as velocity; probability distributions of arbitrary random variables with \\(y\\) as probability densities; etc.\nThe Fundamental Theorem of Calculus\n\\[\nf(b) - f(a) = \\int_a^b f^\\prime (x) dx\n\\tag{1.8}\\]\nWe have already seen an example of this when looking for shaded area under \\(f(x) = x^2\\) between \\(0\\) and \\(1\\) in the previous example:\n\\[\n\\int_0^1 x^2 dx = \\int_0^1 \\frac{d}{dx} \\bigg[ \\frac{1}{3} x^3\\bigg] dx = \\bigg(\\frac{1}{3}x^3\\bigg) \\Bigg|_0^1 = \\frac{1}{3} (1^3) - \\frac{1}{3} (0^3) = \\frac{1}{3}\n\\]\n\n\\(f|_a^b\\) is shorthand for \\(f(b) - f(a)\\)\n\nAntiderivatives"
  },
  {
    "objectID": "prob.html#interpretations",
    "href": "prob.html#interpretations",
    "title": "Probability",
    "section": "Interpretations",
    "text": "Interpretations\nThere are at least three common interpretations of probability.\nThe classical interpretation is based on the idea of equally likely outcomes—i.e., if the outcome of some process must be \\(m\\) of \\(n\\) different outcomes, and these are equally likely to occur, then the probability of \\(m\\) is \\(m/n\\). This interpretation is silly because the idea of “equally likely outcome” is based on the concept of probability that we are trying to define, it’s a tautology.\n\nMost interesting outcomes cannot be assumed to be equally likely!\n\nAn extension of this interpretation leads to an interpretation of probability as a calculus for counting that allows us to represent the plausibility of different events. This is also known as the naive definition of probability. It is very limited because it requires equally likely outcomes and can’t handle uncountable or infinite sample spaces (e.g., areas, continuous time measurements). Better interpretations of probability build upon the same mathematical foundations.\nAccording to the frequentist interpretation, the probability that some specific outcome of a process will be obtained can be interpreted to mean the relative frequency with which that outcome would be obtained if the process were repeated a large number of times and under similar conditions. In other words, probability describes the proportions of specific events that can be expected to occur among many realizations of a random generative process. It’s all about long-term frequencies. Probabilities are the long-term frequency properties of things that we can measure repeatedly. This interpretation is not silly, but it only applies to problems in which there can be (at least in principle) a large number of similar repetitions of a certain process. Many important problems are not of this kind.\n\nWhat number of times is large enough?\nThe conditions must not be “exactly” the same; otherwise the outcomes would be exactly the same!\n\nThe Bayesian interpretation takes a different direction. Here, we treat “randomness” as a property of information, not of or the world. Almost nothing in the world is actually random. Presumably, we could predict everything exactly if we had more information. Thus, we use randomness to describe uncertainty in the face of incomplete knowledge. This is why this is also known as the subjective interpretation of probability.\n\nIt will make some readers uncomfortable to suggest that there is more than one way to define “probability.” Aren’t mathematical concepts uniquely correct? They are not. Once you adopt some set of premises, or axioms, everything does follow logically in mathematical systems. But the axioms are open to debate and interpretation. So not only is there “Bayesian” and “frequentist” probability, but there are different versions of Bayesian probability even, relying upon different arguments to justify the approach.\nMcElreath (2020, 12–13)\n\nRegardless of the ongoing controversy about its interpretation, probability was established as a mathematical theory by Kolmogorov in the early 20th century. And although the different interpretations seem incompatible, the calculus of probability applies equally well no matter which interpretation one prefers. Thus, probability is simply a mathematical tool that allows us allows us to quantify uncertainty and randomness in principled ways."
  },
  {
    "objectID": "prob.html#extra",
    "href": "prob.html#extra",
    "title": "Probability",
    "section": "Extra",
    "text": "Extra\nfile:///Users/acastroaraujo/Documents/Notes/Math/Probability.html\nfile:///Users/acastroaraujo/Documents/Columbia/3.%20Fall/BDA%20-%20Gelman/Notes_-_BDA.html\nfile:///Users/acastroaraujo/Documents/Columbia/1.%20Fall/Probability%20Theory/Other_Stuff.html\nfile:///Users/acastroaraujo/Documents/Columbia/1.%20Fall/Probability%20Theory/Probability.html\nfile:///Users/acastroaraujo/Documents/Old%20Repositories/SelfStudy/Probability-and-Statistics/1-Probability.html\nhttps://acastroaraujo-notebooks.netlify.app/posts/2021-01-27-probability-notes/\nhttps://betanalpha.github.io/assets/case_studies/probability_theory.html#12_sigma_algebras\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. CRC press.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. Vol. 26. Springer."
  },
  {
    "objectID": "prob-intro.html#kolmogorov-axioms",
    "href": "prob-intro.html#kolmogorov-axioms",
    "title": "2  Introduction",
    "section": "2.1 Kolmogorov Axioms",
    "text": "2.1 Kolmogorov Axioms\n\\((\\Omega, S, P)\\) form a probability space when the following conditions hold:\n\nNon-negativity, for any \\(A \\in S\\)\n\n\\[0 \\leq P(A) \\leq 1\\]\n\nNormalization.\n\n\\[P(\\Omega) = 1\\]\n\nCountable additivity, if \\(A_1, A_2, ... \\in S\\) are pairwise disjoint, then\n\n\\[P(A_1 \\cup A_2, \\cup ...) = P(A_1) + P(A_2) + ... \\]\nWe can represent any random generative process as a probability space \\((\\Omega,S,P)\\).\n\n2.1.1 Consequences\nSeveral other fundamental properties of probability follow directly from the Kolmogorov probability axioms:\nLet \\(A, B \\in S\\)\n\nMonotonicity\n\n\\[A \\subseteq B \\to P(A) \\leq P(B)\\]\n\nSubtraction rule\n\n\\[A \\subseteq B \\to P(B \\setminus A) = P(B) - P(A)\\]\n\nSome event in \\(S\\) must occur\n\n\\[P(\\varnothing) = 0\\]\n\nComplement rule\n\n\\[P(A^C) = 1 - P(A)\\]"
  },
  {
    "objectID": "prob-intro.html#joint-and-conditional-probabilities",
    "href": "prob-intro.html#joint-and-conditional-probabilities",
    "title": "2  Introduction",
    "section": "2.2 Joint and Conditional Probabilities",
    "text": "2.2 Joint and Conditional Probabilities\nThe joint probability of of \\(A\\) and \\(B\\) (i.e. that both events will ocur in a single draw from \\((\\Omega, S, P)\\)) is denoted as \\(P(A \\cap B)\\).\nFor example, the probability of rolling a six-sided die and getting \\(A = \\{\\omega \\in \\Omega: \\omega \\geq 4\\}\\) and \\(B = \\{\\omega \\in \\Omega: \\omega \\text{ is even}\\}\\) is as follows:\n\\[\nP(A \\cap B) = P(\\{4, 5, 6\\} \\cap \\{2, 4, 6\\}) = \\frac{|\\{4, 6\\}|}{|\\Omega|} = \\frac{1}{3}\n\\]\n\nAddition rule\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\nThe conditional probability of \\(A\\) given \\(B\\) is denoted as\n\\[P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\\]\n\nProduct rule\n\n\\[P(A \\mid B) P(B) = P(A \\cap B)\\]\n\nBayes’ rule\n\n\\[P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{P(B)}\\]\nThe law of total probability states that if \\(\\{A_1, A_2, A_3, ...\\}\\) is a partition of \\(\\Omega\\) and \\(B \\in S\\), then\n\\[\nP(B) = \\sum_i P(B \\cap A_i) = \\sum_i \\underbrace{P(B \\mid A_i) P(A_i)}_\\text{product rule}\n\\]\nIn other words, the probability of an event \\(B\\) is effectively a weighted average of the conditional probabilities of that event (\\(B\\)).\nEvents and conditional probabilities.\nWhen writing \\(\\Pr(A\\mid E)\\), we do not mean that \\(A \\mid E\\) is an event and that we’re taking its probability.\n\\[A \\mid E \\hspace{0.3cm} \\text{is not an event!}\\]\n\n\\(\\Pr(A \\mid E)\\) is a probability function which assigns probabilities in accordance with the knowledge that \\(E\\) has occurred.\n\\(\\Pr(A)\\) is a different probability function which assigns probabilities without regard for whether \\(E\\) has occurred or not."
  },
  {
    "objectID": "prob-intro.html#independence",
    "href": "prob-intro.html#independence",
    "title": "2  Introduction",
    "section": "2.3 Independence",
    "text": "2.3 Independence\nEvents \\(A, B \\in S\\) are independent if \\(P(A \\cap B) = P(A)P(B)\\). This also implies the following:\n\\[A \\perp B \\iff P(A \\mid B) = P(A)\\]\nThat is, when \\(A\\) and \\(B\\) are independent, knowing whether or not \\(B\\) has occurred gives us no information about the probability that \\(A\\) has occurred. This is a very strong assumption, but it lies in the heart of many applications in statistics that work with independent and identically distributed (i.i.d.) random variables.\n\nConditional independence\n\n\\[A \\perp B \\mid E \\iff P(A \\cap B \\mid E) = P(A \\mid E) P(B \\mid E)\\]\nThis is different from saying that \\(A\\) and \\(B\\) are independent themselves.\nIn general:\n\nTwo events can be conditionally independent given \\(E\\), but not independent.\nTwo events can be independent, but not conditionally independent given \\(E\\).\nTwo events can be conditionally independent given \\(E\\), but not independent given \\(E^C\\)."
  },
  {
    "objectID": "prob-counting.html#sampling",
    "href": "prob-counting.html#sampling",
    "title": "3  Counting Methods",
    "section": "Sampling",
    "text": "Sampling\nTable 3.1 gives the number of possible samples of size \\(k\\) out of a population of size \\(n\\), under various assumptions about how the sample is collected.\n\n\nTable 3.1: Sampling Table\n\n\n\n\n\n\n\n\nOrdered\nUnordered\n\n\nWith replacement\n\\(n^k\\)\n\\(\\binom{n + k - 1}{k}\\)\n\n\nWithout replacement\n\\(\\frac{n}{(n-k)!}\\)\n\\(\\binom{n}{k}\\)\n\n\n\n\n\n\n\n\nBlitzstein, Joseph K., and Jessica Hwang. 2019. Introduction to Probability. Crc Press."
  },
  {
    "objectID": "prob-random-vars.html#basics",
    "href": "prob-random-vars.html#basics",
    "title": "4  Random Variables",
    "section": "4.1 Basics",
    "text": "4.1 Basics\nA random variable, \\(X\\), is a function from the sample space, \\(\\Omega\\), to some subset of \\(\\mathbb{R}\\) with a probability-based rule.\n\\[X: \\Omega \\to \\mathbb R\\]\nRecall that each \\(\\omega \\in \\Omega\\) denotes a state of the world. A random variable \\(X\\) will take take on the value \\(X(\\omega)\\).\nFor example, the event \\(\\{X = 1\\}\\) should be understood the set of of states of the world such that \\(X(\\omega) = 1\\).\n\\[\nP(\\{X = 1\\}) = P(\\{\\omega \\in \\Omega: X(\\omega) = 1\\})\n\\]\nThere are two ways in which to apply functions to random variables:\n\nFunction of a random variable. Use the value of \\(X(\\omega)\\) as input into another function \\(g\\), with the result being another random variable.\n\\[g \\circ X: \\Omega \\to \\mathbb R\\]\nFor example:\n\\[\ng(X) = \\begin{cases} 1 &\\text{if } X>0 \\\\ 0  &\\text{otherwise}\n\\end{cases}\n\\]\nOperator on random variable. These will summarize the properties of random variables such as expectations or variances. We use the \\([\\cdot]\\) notation to denote operators.\n\nWe use uppercase to denote random variables and lowercase to denote particular realizations (or variables in the regular, algebraic sense).\n\nA discrete random variable can only can take on a finite (or countably infinite) number of different values.\nA continuous random variable can take on a continuum of possible values. Loosely speaking, a random variable is continuous if its CDF is continuous."
  },
  {
    "objectID": "prob-random-vars.html#pmfs-pdfs-and-cdfs",
    "href": "prob-random-vars.html#pmfs-pdfs-and-cdfs",
    "title": "4  Random Variables",
    "section": "4.2 PMFs, PDFs, and CDFs",
    "text": "4.2 PMFs, PDFs, and CDFs\nGiven a discrete random variable \\(X\\), we can summarize the probability of each outcome \\(x\\) occurring with a probability mass function (PMF). A continuous random variable is characterized by its probability density function (PDF).\n\\[\n\\underbrace{f(x) = P(X = x)}_\\text{PMF} \\hspace{1cm}\n\\int_a^b \\underbrace{f(x)}_\\text{PDF}dx = P(a \\leq X \\leq b)\n\\]\nNote that both functions must be non-negative\n\\[f(x) \\geq 0 \\hspace{0.5cm} \\text{ for all } x \\in \\mathbb R\\]\nThese functions tell us most of what we need to know about the distribution of random variables (i.e. the complete collection of probabilities assigned to events defined in terms of \\(X\\)).\nThe cumulative distribution function (CDF) tell us everything we need to know about the distribution of random variables. More importantly, a CDF is defined the same way for both discrete and continuous random.\nThe CDF of \\(X\\) is defined as\n\\[F(x) = P(X \\leq x) \\hspace{0.5cm} \\text{ for all } x \\in \\mathbb R\\]\nIn other words, the CDF returns the probability that an outcome for a random variable will be less than or equal to a given value.\nAny CDF \\(F\\) will have the following properties:\n\n\\(F\\) is nondecreasing as \\(x\\) increases\n\n\\[x_1 < x_2 \\to F(x_1) < F(x_2)\\]\n\nLimits\n\n\\[\n\\lim_{x \\to +\\infty} F(x) = 1 \\hspace{0.5cm}\n\\lim_{x \\to -\\infty} F(x) = 0\n\\]\n\nComplement rule\n\n\\[1-F(x) = P(X > x)\\]\n\nContinuity from the right. A CDF is always continuous from the right, even if the random variable is discrete (in which case the CDF is a “step function”).\n\n\\[\\lim_{x \\to a^+} F(x) = F(a)\\]\nIn the case of continuous random variables, note that the PDF is contained inside the definition of the CDF.\n\\[\n\\overbrace{F(a) = P(X \\leq a) = \\int_{-\\infty}^a \\underbrace{f(x)}_\\text{PDF}dx}^\\text{Cumulative Distribution Function}\n\\]\nThat is a probability density is the rate of change in cumulative probability. So where cumulative probability is increasing rapidly, density can easily exceed 1. But if we calculate the area under the density function, it will never exceed 1. In other words, the PDF is a “slope” that is defined according to the Fundamental Theorem of Calculus as follows:\n\\[\\underbrace{f(x) = \\frac{dF(u)}{du} \\bigg|_{u = x}}_\\text{Probability Density Function}\\]\n\nTwo additional definitions.\n\nSupport. . The set of values at which the PMF (or PDF) is positive is called its support.\n\n\\[\n\\textsf{supp}(X) = \\{x \\in \\mathbb R: f(x) > 0\\}\n\\]\n\nThe inverse of a CDF (\\(Q = F^{-1}\\)) is called the quantile function.\nFor example:\n\n\\[\n\\underbrace{Q(0.5)}_\\text{median} = x \\iff P(X \\leq x) = 0.5\n\\]"
  },
  {
    "objectID": "prob-random-vars.html#relationships",
    "href": "prob-random-vars.html#relationships",
    "title": "4  Random Variables",
    "section": "4.3 Relationships",
    "text": "4.3 Relationships\nWhen we say two random variables are equal, we mean that they are equal as functions; they assign the same value to every state of the world.\n\\[\nX = Y \\iff X(\\omega) = Y(\\omega)\\hspace{0.5cm} \\forall \\omega \\in \\Omega\n\\]\nDiscrete multivariate distributions are described by their joint CDF, PMF, or PDF.\n\\[\n\\overbrace{F(a, b) = P(X \\leq a \\cap Y \\leq b) = \\int_{-\\infty}^a \\int_{-\\infty}^b \\underbrace{f(x, y)}_\\text{joint PDF}dy dx}^\\text{Joint Cumulative Distribution Function}\n\\]\nThe same as before, integrating over a PDF will give us probability statements such as\n\\[\nP(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f(x, y)dydx\n\\]\nThe same goes for summing over a PMF:\n\\[\nP(a \\leq X \\leq b, c \\leq Y \\leq d) = \\sum_{x = a}^b \\sum_{y = c}^d f(x, y)\n\\]\nAnd the “slope” interpretation extends to multivariate PDFs:\n\\[\n\\underbrace{f(x, y) = \\frac{\\partial F(u, v)}{\\partial u \\partial v} \\bigg|_{u = x, v = y}}_\\text{Joint Probability Density Function}\n\\]\nAnd for the discrete setting:\n\\[\n\\underbrace{f(x, y) = P(X = x, Y = y)}_\\text{Joint Probability Mass Function}\n\\]\nMarginalization. We can go from multivariate to univariate distributions with summation (for PMFs) or integration (for PDFs). Both of these follow from the law of total probability.\n\nMarginal PMF\n\n\\[\nf_Y(y) = P(Y = y) = \\sum_{\\textsf{supp}[X]} f_{X, Y}(x, y)\n\\]\n\nMarginal PDF\n\n\\[\n\\text{Continuous: }f_Y(y) = \\int_{-\\infty}^\\infty f_{X, Y}(x, y)dx\n\\]\nConditional Distributions. The conditional PMF of \\(Y\\) given \\(X\\) tells us the probability that a given value of \\(Y\\) will occur, given that a certain value of \\(X\\) occurs. In contrast, the conditional PDF of \\(Y\\) given \\(X\\) is just the PDF of \\(Y\\) given that a certain value of \\(X\\) occurs.\n\nConditional PMF\n\n\\[\n\\begin{align}\nf_{Y \\mid X}(y \\mid x) = P(Y = y \\mid X = x) = \\frac{f(x, y)}{f(x)} \\\\\\\\ \\forall y \\in \\mathbb R \\text{ and } \\underbrace{\\forall x \\in \\textsf{supp}(X)}_{\\text{denominator} \\neq 0}\n\\end{align}\n\\]\n\nConditional PDF\n\n\\[\nf_{Y \\mid X}(y \\mid x)  = \\frac{f(x, y)}{f(x)} \\hspace{0.5cm} \\forall y \\in \\mathbb R \\text{ and } \\forall x \\in \\textsf{supp}[X]\n\\]\n\nProduct rule for PMFs and PDFs\n\n\\[\nf(x \\mid y)f(y) = f(x, y)\n\\]\n\nIndependence of random variables regardless of whether they are discrete or continuous.\n\n\\[X \\perp Y \\iff f(x, y) = f(x) f(y)\\]\n\\[X \\perp Y \\iff f(x \\mid y) = f(x)\\]"
  },
  {
    "objectID": "prob-random-vars.html#multivariate-notation",
    "href": "prob-random-vars.html#multivariate-notation",
    "title": "4  Random Variables",
    "section": "4.4 Multivariate Notation",
    "text": "4.4 Multivariate Notation\nA random vector of length \\(K\\) is a vector whose components are random variables:\n\\[\n\\mathbf X (\\omega) = \\pmatrix{X_{[1]} (\\omega), & \\dots, & X_{[K]} (\\omega)}\n\\]\nHere, we use bracketed subscripts to denote distinct random variables because later on we use plain subscripts to denote multiple independent realizations of a single random variable.\nThe use of boldface will make us be able to express complicated expressions in a simple manner.\nFor example:\n\\[\n\\underbrace{F(\\mathbf x)}_\\text{CDF} = P(\\mathbf X \\leq \\mathbf x) = P(X_{[1]} \\leq x_{[1]}, X_{[2]} \\leq x_{[2]}, \\dots, X_{[K]} \\leq x_{[K]})\n\\]\nAnd if we have a continuous random vector, we have the following expression:\n\\[\nF(\\mathbf x) = \\int_{-\\infty}^{x_{[1]}} \\int_{-\\infty}^{x_{[2]}} \\dots \\int_{-\\infty}^{x_{[K]}}  f(u_{[1]}, u_{[2]}, \\dots, u_{[K]})du_{[K]} \\dots du_{[2]}du_{[1]}\n\\]"
  },
  {
    "objectID": "prob-sum-dist.html",
    "href": "prob-sum-dist.html",
    "title": "5  Summarizing Distributions",
    "section": "",
    "text": "6 Summarizing joint distributions"
  },
  {
    "objectID": "prob-sum-dist.html#expectation",
    "href": "prob-sum-dist.html#expectation",
    "title": "5  Summarizing Distributions",
    "section": "5.1 Expectation",
    "text": "5.1 Expectation\nThe expected value (also known as the expectation or mean) is the most common measure of the “center” of a probability distribution.\n\nDiscrete random variables\n\n\\[\nE[X] = \\sum_{\\textsf{supp}(x)} x f(x)\n\\]\n\nContinuous random variables\n\n\\[\nE[X] = \\int_{-\\infty}^\\infty x f(x)dx\n\\]\n\nProperties of expected values\n\n\\[\n\\begin{align}\n&E[c] = c &\\text{ for all } c \\in \\mathbb R \\\\\\\\\n&E[cX] = c\\ E[X]  &\\text{ for all } c \\in \\mathbb R\n\\end{align}\n\\]\n\nExpectation of a Bernoulli random variable\n\n\\[\nE[X] = P(X = 1) = p\n\\]\nExpectation of a function of a random variable (also known as LOTUS). This comes up in many applications (e.g. finding the variance of a random variable), but the result is far from obvious (see here).\n\nContinuous case\n\n\\[E[g(X)] = \\int_{-\\infty}^\\infty g(x) f_X(x) dx\\]\n\nDiscrete case\n\n\\[E[g(X)] = \\sum_{\\textsf{supp}(x)} g(x) f_X(x)\\]\n\nLinearity of expectations\n\n\\[E[aX + bY + c] = aE[X] + bE[Y] + c\\]\nNote that this property follows from considering the expectation of a function of a bivariate joint distribution.\n\\[\\underbrace{g(X, Y) = aX + bY + c}_\\text{function of a bivariate joint distribution}\\]\nApply LOTUS and marginalization:\n\\[\n\\begin{align}\nE[g(X, Y)] &= \\sum_x \\sum_y g(X, Y) f_{XY}(x,y) \\\\\\\\ &=\n\\sum_x \\sum_y (ax + by + c) f_{XY}(x,y) \\\\\\\\ &=\na\\sum_x \\sum_y x f_{XY}(x,y) +  b\\sum_x \\sum_y y f_{XY}(x,y)+ c\\sum_x \\sum_y f_{XY}(x,y)\n\\end{align}\n\\]"
  },
  {
    "objectID": "prob-sum-dist.html#moments-and-variances",
    "href": "prob-sum-dist.html#moments-and-variances",
    "title": "5  Summarizing Distributions",
    "section": "5.2 Moments and variances",
    "text": "5.2 Moments and variances\nWe can generalize expectations to further characterize the features of a distribution. This is the idea of raw moments, among which the expected value is just a special case.\n\\[\n\\underbrace{\\mu_j^\\prime = E[X^j]}_{j^{th}\\text{ raw moment }}\n\\]\nRaw moments provide summary information about a distribution, describing elements of its shape and location.\n\nCentral moments\n\n\\[\\mu_j = E\\left[(X - E[X])^j\\right]\\]\nThe sole distinction between raw and central moments lies in whether or not the expected value of \\(X\\) is subtracted before calculations.\n\nThe variance (second central moment)\n\n\\[\nV[X] = E\\left[(X - E[X])^2\\right] = E\\left[X^2\\right] - E[X]^2\n\\]\nThe variance measures the expected value of the squared difference between the observed value of \\(X\\) and its mean. Note that the first central moment equals zero.\n\nProperties of variances\n\n\\[\n\\begin{align}\n&V[X + c] = V[X] &\\text{ for all } c \\in \\mathbb R \\\\\\\\\n&V[cX] = c^2\\ E[X]  &\\text{ for all } c \\in \\mathbb R\n\\end{align}\n\\]\n\nStandard deviation\n\n\\[\n\\sigma[X] = \\sqrt{V[X]}\n\\]\nThe standard deviation is often preferable to the variance, since it is on the same scale as the random variable of interest.\nKnowing these two quantities (\\(E[X]\\) and \\(\\sigma[X]\\)) tells everything about normal distributions.\n\nThe normal distribution\n\n\\[X \\sim \\textsf{normal}(\\mu, \\sigma)\\]\n\\[\nE[X] = \\mu \\hspace{0.5cm} \\text{ and } \\hspace{0.5cm}\n\\sigma[X] = \\sigma\n\\]\n\\[\nf_X(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp\\left(-\\frac{1}{2 \\sigma^2} (x - \\mu)^2\\right)\n\\]\nAny linear combination of any number of mutually independent normal random variables must itself be normal.\n\\[\nX \\perp Y \\to X + Y \\sim \\textsf{normal}\\left(\\mu_X + \\mu_Y, \\sqrt{\\sigma_X^2 + \\sigma_Y^2}\\right)\n\\]"
  },
  {
    "objectID": "prob-sum-dist.html#mean-squared-error",
    "href": "prob-sum-dist.html#mean-squared-error",
    "title": "5  Summarizing Distributions",
    "section": "5.3 Mean Squared Error",
    "text": "5.3 Mean Squared Error\nMSE is a metric that characterizes how well a random variable \\(X\\) approximates a certain value \\(c\\).\n\\[MSE = E\\left[(X - c)^2\\right]\\]\nNote that the MSE about zero is the same as the second raw moment, and the MSE about \\(E[X]\\) is the same as the second central moment, which is also the variance.\n\nRoot Mean Squared Error\n\\[\\sqrt{E\\left[(X - c)^2\\right]}\\]\nNote. This is used as a common measure of accuracy in the context of estimation.\nDecomposition\n\n\\[\n\\begin{align}\nE\\left[(X - c)^2\\right] &= E\\left[(X^2 - 2cX + c^2\\right] \\\\\\\\ &=\nE\\left[X^2\\right] - 2cE[X] + c^2 \\\\\\\\ &=\nE\\left[X^2\\right] \\underbrace{- E[X]^2 + E[X]^2}_\\text{clever trick} - 2cE[X] + c^2 \\\\\\\\ &=\n\\left(E\\left[X^2\\right] - E[X]^2\\right) + \\left(E[X]^2 - 2cE[X] + c^2\\right) \\\\\\\\ &=\nV[X] + (E[X]-c)^2\n\\end{align}\n\\]\nNote. In the context of estimation, this is also known as the bias-variance decomposition.\nThe MSE is also linked to an alternative definition of the mean: the value \\(c\\) that minimizes the MSE of \\(X\\) is \\(E[X]\\).\n\\[\n\\underset{c \\in \\mathbb R}{\\arg \\min}\\ E\\left[(X - c)^2\\right] = E[X]\n\\]\nIf we where to choose a different “loss function” besides the MSE, we could come up with different “best” choices for \\(c\\). For example, the median is the value \\(c\\) that minimizes the Mean Absolute Error (\\(|X - c|\\))."
  },
  {
    "objectID": "prob-sum-dist.html#covariance",
    "href": "prob-sum-dist.html#covariance",
    "title": "5  Summarizing Distributions",
    "section": "6.1 Covariance",
    "text": "6.1 Covariance\nCovariance measures the extent to which two random variables “move together.”\n\\[\n\\begin{align}\n\\text{Cov}[X, Y] &= E\\big[(X - E[X])(Y - E[Y])\\big] \\\\\\\\ &=\nE[XY] - E[X]E[Y]\n\\end{align}\n\\]\n\nVariance Rule (non-linearity of variances)\n\n\\[V[X + Y] = V[X] + 2\\text{Cov}[X, Y] + V[Y]\\]\n\nVariance is a special case of Covariance\n\n\\[\\text{Cov}[X, X] = V[X]\\]\n\nCovariance of sums\n\n\\[\n\\text{Cov}[X + W, Y + Z] = \\text{Cov}[X, Y] + \\text{Cov}[X, Z] + \\text{Cov}[W, Y] + \\text{Cov}[W, Z]\n\\]\nMuch like standard deviation rescales variance, correlation rescales covariance to make its interpretation clearer. The correlation of two random variables is as follows:\n\\[\n\\rho[X, Y] = \\frac{\\text{Cov}[X, Y]}{\\sigma[X] \\sigma[Y]}\n\\]\nThe correlation \\(\\rho\\) is bounded in \\([-1, 1]\\), a fact that derives from the Cauchy-Schwarz inequality.\nLinear dependence describes the relationship between two random variables where one can be written as a linear function of the other. And correlation measures the degree of linear dependence between two random variables.\n\\[\n\\begin{align}\n&\\rho[X, Y] = 1 \\iff Y = a + bX \\\\\\\\\n&\\rho[X, Y] = -1 \\iff Y = a - bX \\\\\\\\\n&\\text{where } b > 0 \\text{ and } a,b \\in \\mathbb R\n\\end{align}\n\\]\nIf two random variables are linearly independent, then \\(\\text{Cov}[X, Y] = 0\\). This fact follows from the definition of covariance and the application of LOTUS.\n\\[\n\\begin{align}\nE[XY] &= \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty x y f(x, y)dydx \\\\\\\\ &=\n\\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty xy f_X(x)f_Y(y)dydx \\\\\\\\ &=\n\\int_{-\\infty}^\\infty x f_X(x)dx \\int_{-\\infty}^\\infty y f_Y(y) \\\\\\\\ &=\nE[X]E[Y]\n\\end{align}\n\\]\nThat is, no relationship between two random variables implies no linear relationship them. However, the opposite is not true: lack of correlation does not imply independence.\n\\[\nX \\perp Y \\longrightarrow \\text{Cov}[X, Y] = 0\n\\]"
  },
  {
    "objectID": "prob-sum-dist.html#conditional-expectations",
    "href": "prob-sum-dist.html#conditional-expectations",
    "title": "5  Summarizing Distributions",
    "section": "6.2 Conditional Expectations",
    "text": "6.2 Conditional Expectations\nConditional expectations allow us to describe how the “center” of one random variable’s distribution changes once we condition on the observed value of another random variable.\n\nDiscrete case (\\(\\forall x \\in \\textsf{supp}[X]\\))\n\n\\[\nE[Y \\mid X = x] = \\sum_y y f_{Y \\mid X}(y \\mid x)\n\\]\n\nContinuous case (\\(\\forall x \\in \\textsf{supp}[X]\\))\n\n\\[\nE[Y \\mid X = x] = \\int_{-\\infty}^\\infty y f_{Y \\mid X}(y \\mid x)dy\n\\]\nNote that LOTUS can also be applied to conditional expectations of functions of many random variables.\n\\[\nE[g(X, Y) \\mid X = x] = \\int_{-\\infty}^\\infty g(x, y) f_{Y \\mid X}(y \\mid x)dy\n\\]\nUnlike unconditional expectations, \\(E[Y \\mid X = x]\\) is a family of operators on the random vector \\((X, Y)\\) that is indexed by \\(x\\).\nA conditional expectation function (CEF) is just a conditional expectation takes is sometimes denoted by \\(G_Y(x)\\) to emphasize the fact that it’s a function that maps \\(x\\) to \\(E[Y \\mid X = x]\\) rather than the value of \\(E[Y \\mid X = x]\\) at some particular \\(x\\). This notation also emphasizes the fact that it’s a function of \\(x\\), not a function of the random variable \\(Y\\).\nWe write \\(E[X \\mid Y]\\) to denote \\(G_Y(X)\\) which is a function of the random variable of \\(X\\), and thus it’s also a random variable.\nThe CEF is closely linked to various topics such as regression, missing data, and causal inference.\n\nLaw of total expectations (also known as the law of iterated expectations or Adam’s law).\n\\[E[Y] = E\\big[E[Y \\mid X]\\big]\\]\nIt implies that the unconditional expectation can be represented as a weighted average of conditional expectations, where the weights are proportional to the probability distribution of the variable being conditioned on.\nProof\n\n\\[\n\\begin{align}\nE[Y] &= \\sum_y y f_Y(y) \\\\\\\\ &=\n\\sum_y y \\sum_x f_{X, Y}(x, y) \\\\\\\\ &=\n\\sum_x \\sum_y y f_{X \\mid Y}(y \\mid x) f_X(x) \\\\\\\\ &=\n\\underbrace{\\sum_x \\overbrace{\\bigg(\\sum_y y f_{Y \\mid X} (y \\mid x)\\bigg)}^{E[Y \\mid X = x]} f_X (x)}_{E\\big[E[Y \\mid X]\\big]}\n\\end{align}\n\\]\n\nLaw of total variance (also known as Eve’s law).\n\\[V[Y] = \\underbrace{E\\big[V[Y \\mid X]\\big]}_\\text{within-group variation} + \\underbrace{V\\big[E[Y \\mid X]\\big]}_\\text{between-group variation}\\]\nThis theorem allows us to decompose the variability of a random variable \\(Y\\) into the average variability “within” values of \\(X\\) and the variability “across” values of \\(X\\).\nThe ordering of the \\(E\\)’s and \\(V\\)’s spells out \\(EVVE\\), hence the name “Eve’s law”.\nProof.\n\n\\(E[Y] = E\\big[E[Y \\mid X]\\big] = E[G_Y(X)]\\) (Adam’s law)\n\\(E \\big[V[Y \\mid X]\\big] = E\\big[E[Y^2 \\mid X] - G_Y(X)^2\\big] = E\\big[Y^2\\big] - E\\big[G_Y(X)^2\\big]\\)\n\\(V[E[Y \\mid X]] = E\\big[G_Y(X)^2\\big] - E[G_Y(X)]^2 = E\\big[G_Y(X)^2\\big] - E[Y]^2\\)\n\nWe add (2) and (3) to get back to the original definition of \\(V[Y] = E\\big[Y^2\\big] - E[Y]^2\\).\n\nWe can also look at Eve’s law from a different perspective:\n\n“Another way to think about Eve’s law is in terms of prediction. If we wanted to predict someone’s height (\\(Y\\)) based on their age (\\(X\\)) alone, the ideal scenario would be if everyone within an age group had exactly the same height, while different age groups had different heights. Then, given someone’s age, we would be able to predict their height perfectly. In other words, the ideal scenario for prediction is no within-group variation in height, since the within-group variation cannot be explained by age differences. For this reason, within-group variation is also called unexplained variation, and between-group variation is also called explained variation. Eve’s law says that the total variance of \\(Y\\) is the sum of unexplained and explained variation” (Blitzstein & Hwang 2014)."
  },
  {
    "objectID": "prob-sum-dist.html#best-predictors",
    "href": "prob-sum-dist.html#best-predictors",
    "title": "5  Summarizing Distributions",
    "section": "6.3 Best Predictors",
    "text": "6.3 Best Predictors\nSuppose we knew the full joint cumulative distribution function (CDF) of \\(X\\) and \\(Y\\), and then someone gave us a randomly drawn value of \\(X\\). What would be the guess of \\(Y\\) that would have the lowest MSE? The function \\(g(X)\\) that best approximates \\(Y\\) is the CEF.\n\n\\(E[Y|X]\\), is the best (minimum MSE) predictor of \\(Y\\) given \\(X\\).\n\nThis makes the CEF a natural target of inquiry: if the CEF is known, much is known about how \\(X\\) relates to \\(Y\\). But in many cases the CEF can turn out to be an extremely complicated function.\nWhat if we were to restrict ourselves to just linear functions of the form \\(g_Y(x) = a + b X\\)? We could then define the best linear predictor (BLP) of \\(Y\\) given \\(X\\) as the set of values \\((a, b)\\) that minimizes the MSE.\nThe BLP is expressed as:\n\\[\n(\\alpha, \\beta) = \\underset{a, b \\in \\mathbb R}{\\arg \\min}\\ E\\big[(Y - a + b X)^2\\big]\n\\]\nUsing some calculus, one can show that these values are:\n\\[\n\\begin{align}\n&\\alpha = E[Y] - \\frac{\\text{Cov}[X, Y]}{V[X]} E[X] \\\\\\\\\n&\\beta =  \\frac{\\text{Cov}[X, Y]}{V[X]}\n\\end{align}\n\\]\nNote. This expression is identical to the one provided by the method of ordinary least squares (OLS), which is designed to estimate population parameters from sample data.\nThere are two important corollaries that follow from this:\n\nThe BLP is also the best linear approximation of the CEF.\n\n\\[\n(\\alpha, \\beta) = \\underset{a, b \\in \\mathbb R}{\\arg \\min}\\ E\\bigg[\\big(E[Y \\mid X] - (a + b X)\\big)^2\\bigg]\n\\]\n\nIf the CEF is linear, then the CEF is the BLP.\n\nNote that these are some of the implications of independence for conditional expectations:\n\\[\n\\begin{align}\nY \\perp X \\iff &1.\\ E[Y \\mid X] = E[Y] \\\\\\\\ &2. V[Y \\mid X] = V[Y] \\\\\\\\ &3. \\text{ The BLP of } Y \\text{ given } X \\text{ is } E[Y]\n\\end{align}\n\\]\nPlotting the CEF and BLP\nSuppose we have the following random variables and that we are interested in approximating the CEF \\(G_Y(x)\\) with it’s BLP.\n\\[\n\\begin{align}\n&X \\sim \\text{uniform}(0, 1) \\\\\\\\\n&W \\sim \\text{normal}(0, 1) \\\\\\\\\n&Y = 10X^2 + W\n\\end{align}\n\\]\nBy linearity of expectations, can conclude that the CEF is just\n\\[\nE[Y \\mid X] =  10 X^2\n\\]\nAnd that the BLP (after some algebra) is given by\n\\[\n\\begin{align}\n&\\beta = \\frac{10 \\big(E\\big[X^3\\big] - E[X]E\\big[X^2\\big]\\big)}{E\\big[X^2\\big] - E[X]^2} \\\\\\\\\n&\\alpha = E[10X^2 + W] - \\beta E[X]\n\\end{align}\n\\]\nThe final solution is given by integrating over \\(X \\sim \\text{uniform}(0, 1)\\):\n\\[\n(\\alpha, \\beta) = \\left(-\\frac{5}{3}, 10\\right)\n\\]\nAnd plotting both functions over \\(\\textsf{supp}[X]\\) looks like this:\n\n\nCode\nE <- function(m) {\n  output <- integrate(\n    f = function(x) x^m * fX(x), \n    lower = -Inf, upper = Inf\n    )$value\n}\n\nslope <- function() {\n  num <- 10 * (E(3) - E(1) * E(2))\n  denom <- E(2) - E(1)^2\n  return(num / denom)\n}\n\nintercept <- function() {\n  10 * E(2) - slope() * E(1)\n}\n\nCEF <- function(x) 10*x^2\nfX <- function(x) dunif(x, min = 0, max = 1)\n\ntibble(x = c(-1, 2)) %>% \n  ggplot(aes(x)) +\n  geom_function(fun = CEF, color = \"steelblue\") +\n  geom_function(fun = function(x) intercept() + slope()*x, \n                color = \"tomato\") + \n  geom_rect(aes(xmin = 0, xmax = 1, ymin = -Inf, ymax = Inf), \n            alpha = 1/10)\n\n\n\n\n\nHere, the BLP (in red) approximates the CEF (in blue) reasonably well over the domain of \\(X\\). While this is not always the case, it is very often the case in the social and health sciences. The BLP is thus a good “first approximation” in a very literal sense, in that it is an approximation with a first-order polynomial.\nHowever, when the CEF is not linear, one must take care in interpreting the BLP as equivalent to the CEF. In particular, this may pose a problem when attempting to make inferences where \\(X\\) has low probability mass over some parts of the domain of the CEF. This is because under nonlinearity, the BLP depends on the distribution of \\(X\\).\n\nSee here for an interactive demonstration."
  },
  {
    "objectID": "prob-sum-dist.html#properties-of-residuals",
    "href": "prob-sum-dist.html#properties-of-residuals",
    "title": "5  Summarizing Distributions",
    "section": "6.4 Properties of residuals",
    "text": "6.4 Properties of residuals\nWe define deviations (or residuals) with the letter \\(\\epsilon\\) and note that they have similar properties when considering with respect to either the CEF or the BLP.\nProperties of deviations\n\n\n\nProperties of deviations\n\n\n\n\n\n\nCEF\nBLP\n\n\n\n\n\\(\\epsilon = Y - E[Y \\mid X]\\)\n\\(\\epsilon = Y - (\\alpha + \\beta X)\\)\n\n\n\\(E[\\epsilon] = 0\\)\n\\(E[\\epsilon] = 0\\)\n\n\n\\(E[\\epsilon \\mid X] = 0\\)\n\\(E[\\epsilon X] = 0\\) (independence)\n\n\n\\(\\text{Cov}[\\epsilon, g(X)] = 0\\)\n\\(\\text{Cov}[\\epsilon, X] = 0\\)\n\n\n\\(V[\\epsilon \\mid X] = V[Y \\mid X]\\)\n\n\n\n\\(V[\\epsilon] = E\\big[V[Y \\mid X]\\big]\\)"
  },
  {
    "objectID": "prob-transformations.html#ignoring-transformations",
    "href": "prob-transformations.html#ignoring-transformations",
    "title": "6  Transformations",
    "section": "6.1 Ignoring Transformations",
    "text": "6.1 Ignoring Transformations\nLOTUS\nFor simplicity, let’s assume that \\(Y = g(X)\\).\n\\[\n\\underbrace{f_Y(y) = f_X(x) \\left| \\frac{d x}{dy} \\right|}_\\text{Transformation}\n\\]\nWe can then express \\(E[Y]\\) as follows:\n\\[\n\\begin{align}\nE[Y] &= \\int_{-\\infty}^\\infty y\\ f_X(x)\\left| \\frac{d x}{dy} \\right| dy \\\\\\\\ &= \\int_{-\\infty}^\\infty g(x)\\ f_X(x)dx\n\\end{align}\n\\]\nExample: The expectation of a standard log-normal distribution\nSuppose we have the following random variables:\n\n\\(Y = g(X) = e^X\\) and \\(\\frac{dy}{dx} = e^x\\)\n\\(X \\sim \\textsf{normal}(0, 1)\\)\n\nWithout LOTUS. Because \\(f_Y(y)\\) is unknown, we need to first figure it out through the use of transformations. This step can be immensely complicated in other circumnstances.\n\\[f_Y(y) = \\varphi(x) \\left| \\frac{d x}{dy} \\right| = \\varphi(\\log y)\\frac{1}{y}\\]\nWe then obtain the expectation as follows:\n\\[\n\\begin{align}\nE[Y] &= \\int_0^\\infty \\varphi(\\log y) dy \\\\\\\\ &=\n\\int_0^\\infty \\frac{1}{\\sqrt{2 \\pi}} \\exp\\left(- \\frac{1}{2} \\log^2 y\\right) dy \\\\\\\\ &= \\sqrt{e}\n\\end{align}\n\\]\nWith LOTUS we don’t have to deal with transformations. Instead, we delve right to it.\n\\[\n\\begin{align}\nE[g(X)] &= \\int_{-\\infty}^\\infty g(x) \\varphi(x) dx \\\\\\\\ &= \\int_{-\\infty}^\\infty  \\frac{1}{\\sqrt{2 \\pi}} \\exp\\left(x - \\frac{x^2}{2}\\right) \\\\\\\\ &= \\sqrt{e}\n\\end{align}\n\\]\nThus, LOTUS is quicker because we can ignore transformations. More importantly, this method is less prone to mistakes because we don’t have to worry about changing the bounds on the integrals!"
  },
  {
    "objectID": "rn.html",
    "href": "rn.html",
    "title": "Generating Random Numbers",
    "section": "",
    "text": "How do we simulate random numbers from specific probability distributions?\nHow do we use random numbers to do stuff?\n\nThe simplest case involves generating uniform pseudo-random numbers. Methods for generating random numbers from other probability distributions all depend on the uniform random number generator.\nThis set of notes builds upon three black boxes: runif(), sample(), and .Random.seed. It’s no use pretending I know how any of this stuff work.\nADD SOME STUFF FROM THE BOOK I LOANED NICO.\n\nrunif()\nADD EXPLANATION OF THIS.\n\ndunif\n\nfunction (x, min = 0, max = 1, log = FALSE) \n.Call(C_dunif, x, min, max, log)\n<bytecode: 0x7ffe5d9e7a08>\n<environment: namespace:stats>\n\npunif\n\nfunction (q, min = 0, max = 1, lower.tail = TRUE, log.p = FALSE) \n.Call(C_punif, q, min, max, lower.tail, log.p)\n<bytecode: 0x7ffe5daf5ff0>\n<environment: namespace:stats>\n\nqunif\n\nfunction (p, min = 0, max = 1, lower.tail = TRUE, log.p = FALSE) \n.Call(C_qunif, p, min, max, lower.tail, log.p)\n<bytecode: 0x7ffe5dc0e768>\n<environment: namespace:stats>\n\nrunif\n\nfunction (n, min = 0, max = 1) \n.Call(C_runif, n, min, max)\n<bytecode: 0x7ffe5dd316f8>\n<environment: namespace:stats>\n\n\n\n\nsample()\nR also has a function that allows sampling from finite populations. This sample() function can be used with our without replacement.\n\n## toss six coins\nsample(0:1, size = 6, replace = TRUE)\n\n[1] 0 1 0 0 1 1\n\n## permuation of letters A-Z\nsample(LETTERS) \n\n [1] \"E\" \"J\" \"V\" \"A\" \"M\" \"G\" \"L\" \"S\" \"X\" \"W\" \"B\" \"C\" \"O\" \"R\" \"Y\" \"F\" \"K\" \"N\" \"Q\"\n[20] \"D\" \"I\" \"P\" \"U\" \"Z\" \"T\" \"H\"\n\n## sample from a multinomial distribution\np <- c(0.2, 0.3, 0.5)\nx <- sample(1:3, size = 3000, replace = TRUE, prob = p)\ntable(x)\n\nx\n   1    2    3 \n 580  895 1525 \n\ntable(x) / length(x)\n\nx\n        1         2         3 \n0.1933333 0.2983333 0.5083333 \n\n\n\n\n.Random.seed\nNote. There’s an integer vector called .Random.seed in the global environment for every R session. This vector changes every time you generate random numbers or every time you change seeds.\nFor example:\n\nset.seed(111)\nstr(.Random.seed)\n\n int [1:626] 10403 624 -762750981 -378653952 -1193945343 -1238812466 800256759 999955148 -1466969763 438919290 ...\n\nset.seed(222)\nstr(.Random.seed)\n\n int [1:626] 10403 624 1488669722 -588037421 -1945880072 -1874066535 1822860934 510535503 495156548 -856964235 ...\n\nrunif(1) ## generate one random number\n\n[1] 0.9315925\n\nstr(.Random.seed)\n\n int [1:626] 10403 1 -2033833551 328541280 -1581583874 -1734191735 219878075 -974258550 -1901840020 939491055 ...\n\nset.seed(111)\nstr(.Random.seed)\n\n int [1:626] 10403 624 -762750981 -378653952 -1193945343 -1238812466 800256759 999955148 -1466969763 438919290 ..."
  },
  {
    "objectID": "rn-methods.html#the-inverse-transform-method",
    "href": "rn-methods.html#the-inverse-transform-method",
    "title": "7  Methods",
    "section": "7.1 The Inverse Transform Method",
    "text": "7.1 The Inverse Transform Method"
  },
  {
    "objectID": "rn-methods.html#the-acceptance-rejection-method",
    "href": "rn-methods.html#the-acceptance-rejection-method",
    "title": "7  Methods",
    "section": "7.2 The Acceptance-Rejection Method",
    "text": "7.2 The Acceptance-Rejection Method"
  },
  {
    "objectID": "rn-methods.html#transformations",
    "href": "rn-methods.html#transformations",
    "title": "7  Methods",
    "section": "7.3 Transformations",
    "text": "7.3 Transformations"
  },
  {
    "objectID": "rn-methods.html#sums-and-mixtures",
    "href": "rn-methods.html#sums-and-mixtures",
    "title": "7  Methods",
    "section": "7.4 Sums and Mixtures",
    "text": "7.4 Sums and Mixtures\nhttp://www.columbia.edu/~ks20/4404-Sigman/4404-Notes-ITM.pdf\nhttps://stephens999.github.io/fiveMinuteStats/inverse_transform_sampling.html\nhttps://en.wikipedia.org/wiki/Inverse_transform_sampling"
  },
  {
    "objectID": "rn-mcmc.html",
    "href": "rn-mcmc.html",
    "title": "9  MCMC",
    "section": "",
    "text": "all from the rizzo book"
  },
  {
    "objectID": "cm.html",
    "href": "cm.html",
    "title": "Correlation Matrices",
    "section": "",
    "text": "This section follows the structure of Hadd and Rodgers (2020).\n\nWhat are correlation matrices? Some math here.\nHow to test correlation matrices? Some null hypothesis testing here.\nHow to model correlation matrices? Some PCA, CFA, and SEM here.\nHow to visualize correlation matrices? This section contains some stuff about geometry and correlation space.\n\n\n\n\n\nHadd, Alexandria, and Joseph Lee Rodgers. 2020. Understanding Correlation Matrices. SAGE Publications."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Blitzstein, Joseph K., and Jessica Hwang. 2019. Introduction to\nProbability. Crc Press.\n\n\nHadd, Alexandria, and Joseph Lee Rodgers. 2020. Understanding\nCorrelation Matrices. SAGE Publications.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course\nwith Examples in r and Stan. CRC press.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in\nStatistical Inference. Vol. 26. Springer."
  },
  {
    "objectID": "computing.html",
    "href": "computing.html",
    "title": "Technical Computing",
    "section": "",
    "text": "Underneath, it’s the 1970s, UNIX, and the command-line.\nTechnical computing is deeply frustrating. And yet it’s weirdly satisfying once you get to subdue the machine and get it to do your will.\nAll of these tools are about controlling the process.\n\nhttps://missing.csail.mit.edu/\nUNIX tools:\n\n\n\n\n\n\nNote\n\n\n\nWindows:\n\ngit bash\ncygwin\n\n\n\nError music video\nExercises:\n\nunzip a docx file\n\nThe File System\ncopy picture of filing cbinet; copy picture of file system hierarchy\n\n\nOffice Model\n\nFormatted documents are real.\nIntermediate outputs are cut and pasted into documents.\nChanges are tracked inside files.\nFinal output is often in the same format you’ve been working in, e.g. a Word file, or a PDF.\n\n\n\nEngineering model\n\nPlain-text files are real.\nIntermediate outputs are produced via code, often inside documents.\nChanges are tracked outside files, at the level of a project.\nFinal outputs are assembled programatically and converted to some desired format.\n\n\n\nThe Unix way of thinking\nWhy is it good to think of things as a collection o files?\nThe Unix conception of a “file” is very flexible. Everything is a file—e.g., connections to other computers or processes can act like files.\nUnix commands are often composable using pipes (|)\nNavigating the tree.\n\nwhoami: Who am I?\npwd: Where am I?\nls: What is in here?\n\nOther commands:\n\nBasic file-handling commands such as cp (copy), mv (move or rename), rm (remove or delete), and chmod (change file permissions)\nBasic file-viewing commands such as cat (view an entire file) and less (view one page at a time)\nBasic directory commands such as cd (change directory), ls (list files in a directory), mkdir (create directory), rmdir (remove directory), and pwd (display your current directory name)\nThe basics of shell scripts: storing Linux commands in a file, making the file executable (with chmod 755 or chmod +x), and running the file\nViewing Linux’s built-in documentation, known as manpages, with the man command (example: man cat displays documentation on the cat command)\n\nCommand Interpreter\nA shell is an interpreter. It waits for commands. When you supply them, it does what you tell it.\n\n\nCode\necho \"hello there\"\npwd\n\n\nhello there\n/Users/acastroaraujo/Documents/Repositories/stats_bb"
  },
  {
    "objectID": "computing-rcpp.html",
    "href": "computing-rcpp.html",
    "title": "14  RCPP",
    "section": "",
    "text": "This notebook focuses on converting simple R functions to C++. It barely scratches the surface of what you can do with C++. For more advanced stuff, check out https://www.learncpp.com/\n\n\nTypical bottlenecks that C++ can address include:\n\nLoops that can't be easily vectorised because subsequent iterations depend on previous ones.\nRecursive functions, or problems which involve calling functions millions of times. The overhead of calling a function in C++ is much lower than in R.\nProblems that require advanced data structures and algorithms that R doesn't provide. Through the standard template library (STL), C++ has efficient implementations of many important data structures, from ordered maps to double-ended queues.\n\nWickham (2019, pp. ?)\n\n\n\n\n\nWickham, Hadley. 2019. Advanced r. CRC press."
  },
  {
    "objectID": "computing-rcpp.html#introduction",
    "href": "computing-rcpp.html#introduction",
    "title": "14  RCPP",
    "section": "14.1 Introduction",
    "text": "14.1 Introduction\n\nTypical bottlenecks that C++ can address include:\n\nLoops that can't be easily vectorised because subsequent iterations depend on previous ones.\nRecursive functions, or problems which involve calling functions millions of times. The overhead of calling a function in C++ is much lower than in R.\nProblems that require advanced data structures and algorithms that R doesn't provide. Through the standard template library (STL), C++ has efficient implementations of many important data structures, from ordered maps to double-ended queues.\n\nWickham (2019, pp. ?)\n\n\n\n\n\nWickham, Hadley. 2019. Advanced r. CRC press."
  },
  {
    "objectID": "computing-rcpp.html#using-rcpp",
    "href": "computing-rcpp.html#using-rcpp",
    "title": "14  RCPP",
    "section": "14.1 Using Rcpp",
    "text": "14.1 Using Rcpp\n\nTypical bottlenecks that C++ can address include:\n\nLoops that can’t be easily vectorised because subsequent iterations depend on previous ones.\nRecursive functions, or problems which involve calling functions millions of times. The overhead of calling a function in C++ is much lower than in R.\nProblems that require advanced data structures and algorithms that R doesn’t provide. Through the standard template library (STL), C++ has efficient implementations of many important data structures, from ordered maps to double-ended queues.\n\nWickham (2019, pp. ?)\n\nNote. C++ is object-oriented in the same way that Python is (i.e., encapsulated OPP); this means we call methods with a “.” like this: object.method().\nThree big differences:\n\nIn C++, vector indices start at zero!\nUse = for assignment instead of <-.\nThe syntax for “for loops” is different: for(init; check; increment) {}.\nFor example, a function that sums all elements in a vector:\n\ncppFunction(\"\ndouble sumC(NumericVector x) {\n  int n = x.size();\n  double result = 0;\n\n  for (int i = 0; i < n; ++i) {\n    result += x[i];\n  }\n  return result;\n}\")\n\nsum(1:20)\n\n[1] 210\n\nsumC(1:20) ## almost as fast!\n\n[1] 210\n\n\n\nNote. There are a few more differences, such as that C++ uses pow(x, 3) instead of x^3, or that it has modify-in-place operators like +=, -=, *=, and /=.\nUsually it’s better not to use cppFunction() and instead source stand-alone files directly using sourceCPP(), analogous to R’s source() function.\nStand-alone files should have a .cpp extension, analogous to the .R extension for regular scripts. Everyone of these files must be structured as follows:\n\n#include <Rcpp.h>\nusing namespace Rcpp;\n\n// [[Rcpp::export]]\ndouble meanC(NumericVector x) {\n  int n = x.size();\n  double total = 0;\n\n  for(int i = 0; i < n; ++i) {\n    total += x[i];\n  }\n  return total / n;\n}\n\n\n\n14.1.1 Exercises\n\nFor each of the following functions, read the code and figure out what the corresponding base R function is. You might not understand every part of the code yet, but you should be able to figure out the basics of what the function does.\n\n\n#include <Rcpp.h>\nusing namespace Rcpp;\n\ndouble f1(NumericVector x) {\n  int n = x.size();\n  double y = 0;\n\n  for(int i = 0; i < n; ++i) {\n    y += x[i] / n;\n  }\n  return y;\n}\n\nNumericVector f2(NumericVector x) {\n  int n = x.size();\n  NumericVector out(n);\n\n  out[0] = x[0];\n  for(int i = 1; i < n; ++i) {\n    out[i] = out[i - 1] + x[i];\n  }\n  return out;\n}\n\nbool f3(LogicalVector x) {\n  int n = x.size();\n\n  for(int i = 0; i < n; ++i) {\n    if (x[i]) return true;\n  }\n  return false;\n}\n\nint f4(Function pred, List x) {\n  int n = x.size();\n\n  for(int i = 0; i < n; ++i) {\n    LogicalVector res = pred(x[i]);\n    if (res[0]) return i + 1;\n  }\n  return 0;\n}\n\nNumericVector f5(NumericVector x, NumericVector y) {\n  int n = std::max(x.size(), y.size());\n  NumericVector x1 = rep_len(x, n);\n  NumericVector y1 = rep_len(y, n);\n\n  NumericVector out(n);\n\n  for (int i = 0; i < n; ++i) {\n    out[i] = std::min(x1[i], y1[i]);\n  }\n\n  return out;\n}\n\nAnswer:\n\nf1 is mean()\nf2 is cumsum()\nf3 is any()\nf4 is Position() or purrr::detect_index()\nf5 is pmin()\n\n\nTo practice your function writing skills, convert the following functions into C++. For now, assume the inputs have no missing values.\n\nall().\ncumprod(), cummin(), cummax().\ndiff(). Start by assuming lag 1, and then generalize for lag n.\nrange().\nvar(). Read about the approaches you can take on Wikipedia. Whenever implementing a numerical algorithm, it’s always good to check what is already known about the problem.\n\n\n\n#include <Rcpp.h>\nusing namespace Rcpp;\n\n// [[Rcpp::export]]\nbool allC(LogicalVector x) {\n  int n = x.size();\n  \n  for (int i = 0; i < n; ++i) {\n    if (!x[i]) return(false);\n  }\n  return true;\n}\n\n// [[Rcpp::export]]\nNumericVector cumprodC(NumericVector x) {\n  int n = x.size();\n  NumericVector out(n);\n  \n  out[0] = x[0];\n  for (int i = 1; i < n; ++i) {\n    out[i] = out[i-1] * x[i];\n  }\n  return out;\n}\n\n// [[Rcpp::export]]\nNumericVector cumminC(NumericVector x) {\n  int n = x.size();\n  NumericVector out(n);\n  \n  out[0] = x[0];\n  for (int i = 1; i < n; ++i) {\n    out[i] = std::min(out[i-1], x[i]);\n  }\n  return out;\n}\n\n// [[Rcpp::export]]\nNumericVector cummaxC(NumericVector x) {\n  int n = x.size();\n  NumericVector out(n);\n  \n  out[0] = x[0];\n  for (int i = 1; i < n; ++i) {\n    out[i] = std::max(out[i-1], x[i]);\n  }\n  return out;\n}\n\n// [[Rcpp::export]]\nNumericVector diffC(NumericVector x, int lag) {\n  int n = x.size() - lag;\n  NumericVector out(n);\n  \n  if (lag < 1) stop(\"`lag` must be an integer >= 1\");\n  \n  for (int i = 0; i < n; ++i) {\n    out[i] = x[i + lag] - x[i];\n  }\n  return out;\n}\n\n// [[Rcpp::export]]\nNumericVector rangeC(NumericVector x) {\n  int n = x.size();\n  double omin = x[0], omax = x[0];\n  \n  for (int i = 1; i < n; ++i) {\n    omin = std::min(omin, x[i]);\n    omax = std::max(omax, x[i]);\n  }\n  \n  NumericVector out(2);\n  out[0] = omin; out[1] = omax;\n  return out;\n  \n}\n\n// [[Rcpp::export]]\ndouble varC(NumericVector x) {\n  int n = x.size();\n  if (n < 2) return NA_REAL;\n  \n  double mu = 0;\n  for (int i = 0; i < n; ++i) mu += x[i];\n  mu /= n;\n  \n  double out = 0;\n  for (int i = 0; i < n; ++i) {\n    out += pow(x[i] - mu, 2);\n  }\n  \n  return out / (n - 1);\n\n}"
  },
  {
    "objectID": "computing-rcpp.html#standard-template-library",
    "href": "computing-rcpp.html#standard-template-library",
    "title": "14  RCPP",
    "section": "14.2 Standard Template Library",
    "text": "14.2 Standard Template Library\n\nThe real strength of C++ is revealed when you need to implement more complex algorithms. The standard template library (STL) provides a set of extremely useful data structures and algorithms.\nWickham (2019, pp. ?)\n\nIterators\n\nIterators are used extensively in the STL: many functions either accept or return iterators. They are the next step up from basic loops, abstracting away the details of the underlying data structure. Iterators have three main operators:\n\nAdvance with ++.\nGet the value they refer to, or dereference, with *.\nCompare with ==.\n\nFor example we could re-write our sum function using iterators:\n\n\n#include <Rcpp.h>\nusing namespace Rcpp;\n\n// [[Rcpp::export]]\ndouble sum3(NumericVector x) {\n  double total = 0;\n  \n  NumericVector::iterator it;\n  for(it = x.begin(); it != x.end(); ++it) {\n    total += *it;\n  }\n  return total;\n}\n\n\nThe main changes are in the for loop:\n\nWe start at x.begin() and loop until we get to x.end(). A small optimization is to store the value of the end iterator so we don't need to look it up each time. This only saves about 2 ns per iteration, so it's only important when the calculations in the loop are very simple.\nInstead of indexing into x, we use the dereference operator to get its current value: *it.\nNotice the type of the iterator: NumericVector::iterator. Each vector type has its own iterator type: LogicalVector::iterator, CharacterVector::iterator, etc.\n\n\nData Structures\n\nThe STL provides a large set of data structures: array, bitset, list, forward_list, map, multimap, multiset, priority_queue, queue, deque, set, stack, unordered_map, unordered_set, unordered_multimap, unordered_multiset, and vector. The most important of these data structures are the vector, the unordered_set, and the unordered_map.\n\nVectors\nMore…\n\n\n\n\nWickham, Hadley. 2019. Advanced r. CRC press."
  },
  {
    "objectID": "calculus.html#derivatives",
    "href": "calculus.html#derivatives",
    "title": "Calculus",
    "section": "Derivatives",
    "text": "Derivatives\nLimit Definition\n\\[\n\\begin{align}\nf'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}, &&\\text{provided the limit exists}\n\\end{align}\n\\tag{1}\\]\nDerivatives are used to understand instantaneous rates of change, i.e., when \\(\\Delta x \\approx 0\\).\nThis formula is equivalent:\n\\[\nf^\\prime (a) = \\lim_{b \\to a} \\frac{f(b) - f(a)}{b-a}\n\\]\nFor example, the area of a growing square is \\(A(x) = x^2\\). How does \\(A(x)\\) change every time \\(x\\) changes? We have that, for any given value of \\(x\\), the rate of instantaneous change is given by:\n\\[\n\\begin{align}\nA^\\prime (x) = 2x && \\text{or} && \\frac{dA}{dx} = 2x\n\\end{align}\n\\]\nNote. When \\(\\Delta\\) is infinitely small we change notation to \\(d\\).\nIf we zoom in on any function at a given point \\(a\\), a tangent line at \\(a\\) will be given by the following formula:\n\\[\ny = f(a) + f^\\prime (a) (x-a)\n\\]\n\nlinear approximation of \\(f\\) near \\(x=a\\)\n\nCritical points\n\\(c\\) is a critical point for the smooth function \\(f\\) iff \\(f^\\prime(c) = 0\\).\nIn order to figure out if \\(c\\) is a local maximum or local minimum, we use the second derivative. The second derivative of \\(f\\) measures the rate of change of the first derivative. In a nutshell, we find critical points by solving \\(f^\\prime = 0\\). We then plug these values into \\(f^{\\prime\\prime}\\). If the result is positive, the critical point is a local minimum; if the result is negative, the critical point is a local maximum.\nThis procedure does not always work.\nNote. For higher order derivatives we use the \\(f^{(n)}(x)\\) notation, where \\(f^{(0)}(x) = f(x)\\). We can also use the symbol \\(\\frac{d^nf}{dx^n}\\) for this purpose.\nDerivative Rules:\nThe constant rule—i.e., constants can move into and out of derivatives.\n\\[\n\\frac{d}{dt} \\bigg[c f(t) \\bigg] = c \\frac{d}{dt} \\bigg[f(t)\\bigg] = c \\cdot f^\\prime (t)\n\\tag{2}\\]\nThe sum rule—i.e., the derivative of the sum is the sum of the derivatives.\n\\[\n\\frac{d}{dt}\\bigg[ f(t) + g(t) \\bigg] = f^\\prime (t) + g^\\prime (t)\n\\tag{3}\\]\nThe product rule.\n\\[\n\\frac{d}{dx} \\bigg[f(x) g(x) \\bigg] = f(x) g^\\prime (x) + g(x) f^\\prime(x)\n\\tag{4}\\]\nThe power rule.\n\\[\n\\frac{d}{dx} \\bigg[ x^n\\bigg] = n \\cdot x^{n-1}\n\\tag{5}\\]\nNote. All these rules make it possible to estimate the derivative of any polynomial of the form \\(c_nx^n + c_{n-1} x^{n-1} + \\dots + c_1\\).\nThe chain rule allows us to find derivatives of compositions.\n\\[\n\\frac{d}{dx} \\bigg[ (f \\circ g)(x) \\bigg] = f^\\prime (g(x)) \\cdot g^\\prime (x)\n\\tag{6}\\]\n\n\\[\n(f \\circ g)(x) = f(g(x))\n\\]\n\nWe can use Equation 5 and Equation 6 to figure out the following:\n\\[\n\\frac{d}{dx} \\bigg[ \\frac{1}{g(x)} \\bigg] = - \\frac{g^\\prime (x)}{g(x)^2}\n\\]\nUsing this with Equation 4, we can figure out the quotient rule:\n\\[\n\\frac{d}{dx} \\bigg[ \\frac{f(x)}{g(x)}\\bigg] = f^\\prime (x) \\Bigg( \\frac{1}{g(x)} \\Bigg) + f(x) \\Bigg(- \\frac{g^\\prime (x)}{g(x)^2} \\Bigg) = \\frac{f^\\prime (x) g(x) - f(x) g^\\prime (x)}{g(x)^2}\n\\tag{7}\\]"
  },
  {
    "objectID": "calculus.html#integrals",
    "href": "calculus.html#integrals",
    "title": "Calculus",
    "section": "Integrals",
    "text": "Integrals\nWhat is the area \\(A(a, b)\\) below the graph \\(y = f(x) \\geq 0\\), above the \\(x\\)-axis, and between \\(x=a\\), and \\(x=b\\)? We can estimate \\(A(a, b)\\) with a sum, and then argue that the estimate becomes exact as the number of terms approximates \\(\\infty\\). This is called a Riemann sum.\n\\[\nA(a, b) = \\underbrace{\\int_a^b \\overbrace{f(x)}^{\\small \\text{integrand}} dx}_\\text{integral}\n\\]\nThe elongated “s” stands for “sum,” when the number of terms to be summed approaches infinity. The decorations on the “s” are called the lower and upper limits of integration.\nThe symbols \\(f(x) \\cdot dx\\) make it clear that the terms of a Riemann sum are the areas of rectangles:\n\\[\n\\begin{align}\n\\text{base: } (x_{n+1} - x_n), &&\\text{height: }f \\bigg( \\frac{x_n + x_{n+1}}{2} \\bigg)\n\\end{align}\n\\]\nFor example,\n\\[\n\\int_0^1 x^2 dx = \\frac{x^3}{3} \\Bigg|_0^1 = \\frac{1^3}{3} - \\frac{0^3}{3} = \\frac{1}{3}\n\\]\nrepresents the area shaded in pink in the following graph:\n\n\nCode\nggplot() + \n  xlim(-0.5, 1.5) + \n  geom_function(fun = \\(x) x^2) +\n  stat_function(geom = \"area\", fun = \\(x) x^2, xlim = c(0, 1), fill = \"pink\") + \n  labs(x = \"x\")\n\n\n\n\n\n\n\nCode\nintegrate(\\(x) x^2, lower = 0, upper = 1)\n\n\n0.3333333 with absolute error &lt; 3.7e-15\n\n\nCode\nn &lt;- 100\nx &lt;- seq(0, 1, length.out = n)\n\nresult &lt;- 0\nfor (i in 1:(n - 1)) {\n  result &lt;- result + (x[i + 1] - x[i]) * ((x[i] + x[i + 1])/2)^2\n}\n\nresult\n\n\n[1] 0.3333248\n\n\n\n100 is much smaller than \\(\\infty\\)\n\nWe use the area under the curve in this graph to think about many things—e.g., displacement of an object with \\(x\\) as time and \\(y\\) as velocity; probability distributions of arbitrary random variables with \\(y\\) as probability densities; etc.\nThe Fundamental Theorem of Calculus\n\\[\nf(b) - f(a) = \\int_a^b f^\\prime (x) dx\n\\tag{8}\\]\nWe have already seen an example of this when looking for shaded area under \\(f(x) = x^2\\) between \\(0\\) and \\(1\\) in the previous example:\n\\[\n\\int_0^1 x^2 dx = \\int_0^1 \\frac{d}{dx} \\bigg[ \\frac{1}{3} x^3\\bigg] dx = \\bigg(\\frac{1}{3}x^3\\bigg) \\Bigg|_0^1 = \\frac{1}{3} (1^3) - \\frac{1}{3} (0^3) = \\frac{1}{3}\n\\]\n\n\\(f|_a^b\\) is shorthand for \\(f(b) - f(a)\\)\n\nAnti-derivatives\nIf \\(F^\\prime (x) = f(x)\\), then the definite integral of \\(f\\) over \\([a,b]\\) is\n\\[\n\\int_a^b f(x) dx = F(b) - F(a)\n\\]\nThe function \\(F(x)\\) is called an anti-derivative of \\(f(x)\\).\nAll anti-derivatives of \\(f(x)\\) are given by \\(F(x) + C\\) for any constant of integration \\(C\\).\nThe Power Rule\n\\[\n\\begin{align}\n\\int x^n dx = \\frac{1}{n+1} x^{n+1} + C, &&\\text{for } n \\neq -1\n\\end{align}\n\\]\nand for \\(n=1\\) we have\n\\[\n\\int x^{-1} dx = \\ln |x| + C\n\\]\nNote. We use “\\(\\int\\)” for anti-derivatives because they are closely related to integrals thanks to the fundamental theorem of calculus shown in Equation 8.\nThe Sum Rule\n\\[\n\\int \\bigg[ f(x) + g(x) \\bigg] dx = \\int f(x) dx + \\int g(x) dx\n\\]\nThe Constant Rule\n\\[\n\\int \\bigg[ c f(x) \\bigg] dx = c \\int f(x) dx\n\\]"
  },
  {
    "objectID": "calculus.html#infinite-sums",
    "href": "calculus.html#infinite-sums",
    "title": "Calculus",
    "section": "Infinite Sums",
    "text": "Infinite Sums\nPreliminary remarks\nA sequence \\(A_n\\) is an ordered list of numbers where the index \\(n\\) is drawn from a fixed subset of the integers. In general, the sequence \\(A_n\\) has a limit \\(L\\) if we can make \\(|A_n - L|\\) as small as we like by picking \\(n\\) large enough.\n\\[\n\\lim_{n \\to \\infty} A_n= L\n\\]\nExample: logistic sequence.\nSuppose a population \\(p_n\\) that increases in size over time relative to some carrying capacity (thus, \\(p\\) is a proportion).\n\\[\np_{n+1} = c \\times p_n \\times (1 - p_n)\n\\]\n\nrecursive equation\n\nHere, \\(c\\) is a positive constant. If the population growth given by this formula eventually stabilizes, we can think of the long-term population as \\(\\lim_{n \\to \\infty} p_n\\), assuming that this limit actually exists.\n\\[\nL = \\frac{c-1}{c}\n\\]\n\nPlug in \\(L\\) for both \\(p_n\\) and \\(p_{n+1}\\) and solve for \\(L\\).\n\nHowever, we don’t know if the \\(\\lim_{n \\to \\infty} p_n\\) actually exists for all values of \\(c\\) and \\(p_o\\) (it doesn’t).\nInfinite sums\nAn infinite sum is the limit of the sequence of partial sums:\n\\[\n\\sum_{j = 1}^\\infty a_j = \\lim_{n \\to \\infty} \\sum_{j = 1}^n a_j\n\\tag{9}\\]\nWhen this limit exists, we say that the sum converges; otherwise we say that it diverges.\nExample: the geometric sum\n\\[\n\\sum_{j=0}^\\infty r^j\n\\]\nGeometric sums have a special place in calculus for a variety of reasons, the most important being that we know precisely when they converge and what they converge to.\nIt’s useful to think of the following sequences:\n\\[\n\\begin{align}\nS_n &= 1 + r + r^2 + \\dots + r^n, \\\\\nS_{n+1} &= 1 + r + r^2 + \\dots r^{n+1}\n\\end{align}\n\\]\nFrom which we can establish that:\n\\[\n\\begin{align}\nS_{n+1} &= r S_n + 1, \\\\\nS_{n+1} &= S_n + r^{n+1}\n\\end{align}\n\\]\n\nMultiply \\(S_n\\) by \\(r\\) and add \\(1\\) to get the first equation.\n\nAs it turns out, the geometric sum converges if \\(|r| &lt; 1\\) and diverges if \\(|r| \\geq 1\\).\nAssuming that the limit exists, and thus \\(|r| &lt; 1\\), we can get the following:\n\\[\n\\lim_{j \\to \\infty} \\sum_{j=0}^j r^j = \\frac{1}{1-r}\n\\]\n\nRemember to plug in \\(L\\) for both \\(S_{n+1}\\) and \\(S_n\\)."
  },
  {
    "objectID": "calculus.html#other",
    "href": "calculus.html#other",
    "title": "Calculus",
    "section": "Other",
    "text": "Other\n\nEuler’s number\nEuler’s number \\(e\\) is defined in terms of a limit approaching infinity.\n\\[\ne = \\lim_{n \\to \\infty} \\bigg( 1 + \\frac{1}{n} \\bigg)^n \\approx 2.718282...\n\\]\nWe also call this a horizontal asymptote.\n\n\nCode\nfoo &lt;- function(x) (1 + 1/x)^x\n\nggplot() + \n  xlim(-5, 50) +\n  coord_cartesian(ylim = c(0.5, 5)) +\n  labs(x = \"n\", y = \"f(n)\") +\n  geom_function(fun = foo,  n = 1e3) + \n  geom_hline(yintercept = exp(1), linetype = \"dashed\")\n\n\n\n\n\nNote that the limit is undefined as \\(n \\to 0\\).\nExponential functions\n\nWho has not been amazed to learn that the function \\(y=e^x\\), like a phoenix rising again from its own ashes, is its own derivative?\n\nAn exponential function has the form \\(f(x) = b^x\\) where \\(b&gt;0\\) is constant called the base and \\(x\\) sits in the exponent.\nThe base \\(e=2.71828 \\dots\\) is called Euler’s number.\nAll exponential functions are proportional to their own derivatives, but \\(e\\) alone is the special number for which this proportionality constant is \\(1\\).\nFor example, take the following function:\n\\[\n\\begin{align}\nM(t) = 2^t, && \\lim_{h \\to 0} M = \\frac{\\overbrace{2^t 2^{h}}^{2^{t + h}} - 2^t}{h} = 2^t \\bigg( \\frac{2^{h}-1}{h} \\bigg)\n\\end{align}\n\\]\nHere, the value \\((2^h - 1) / h\\) is a constant approximately equal to \\(0.6931472\\).\nThus, by definition, we have the following equation:\n\\[\n\\lim_{h \\to 0} \\frac{e^h - 1}{h} = 1\n\\]\nAnd so, the derivative of \\(e^x\\) turns out to be \\(e^x\\) itself.\n\\[\n\\frac{d}{dx}e^x = e^x \\cdot 1\n\\]\nWith this, we can use the chain rule to get the derivative of the more general form:\n\\[\n\\frac{d}{dt}e^{ct} = c \\cdot e^{ct}\n\\]\nFinally, we now have a way to express any proportionality constant in terms of generic natural logarithms (logarithms with base \\(e\\)), once we remember that \\(\\log_e (x) = c\\), so that \\(x = e^c\\).\n\\[\n\\frac{d}{dt} 2^t = \\frac{d}{dt} e^{\\ln(2)t} = \\ln(2) e^{\\ln(2)t}\n\\]\nThe derivative of \\(2^t\\) is itself multiplied by some proportionality constant equal to \\(\\ln(2)\\).\n\n\nCode\nlog(2, base = exp(1))\n\n\n[1] 0.6931472\n\n\n\n\nTaylor Series\nA smooth function \\(f\\) can be approximated near any given point \\(x=a\\) by\n\\[\ny = \\underbrace{\\overbrace{f(a) + f^{(1)} (a) (x-a)}^\\text{linear approximation} + \\frac{1}{2!}f^{(2)}(a)(x-a)^2}_{\\text{quadratic approximation}} + \\frac{1}{3!}f^{(3)}(a)(x-a)^3 + \\dots\n\\]\nIf we keep going, we end up with a Taylor series of \\(f\\) centered at \\(a\\):\n\\[\n\\sum_{n=0}^\\infty \\frac{f^{(n)}(a)}{n!} (x - a)^n\n\\]\nFor example,the Taylor series of \\(e^x\\) centered at \\(0\\) is given by:\n\\[\ne^x = \\sum_{n = 0}^\\infty \\frac{x^n}{n!}\n\\]\n\n\nCode\nexp_taylor_zero &lt;- function(x, degree) {\n  \n  f &lt;- purrr::map(0:degree, function(n) {\n    function(x) x^n / factorial(n)\n  })\n  \n  purrr::map_dbl(x, function(x) {\n    out &lt;- vector(\"double\", length(f))\n    for (i in seq_along(out)) out[[i]] &lt;- f[[i]](x)\n    return(sum(out))\n  })\n}\n\nggplot() + \n  xlim(-2, 4) + \n  geom_function(fun = exp, linewidth = 2) + \n  geom_function(fun = \\(x) exp_taylor_zero(x, degree = 1), aes(color = \"1\")) +\n  geom_function(fun = \\(x) exp_taylor_zero(x, degree = 2), aes(color = \"2\")) +\n  geom_function(fun = \\(x) exp_taylor_zero(x, degree = 3), aes(color = \"3\")) +\n  geom_function(fun = \\(x) exp_taylor_zero(x, degree = 9), aes(color = \"9\")) + \n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  labs(x = \"x\", y = expression(e^x), color = \"degree\")\n\n\n\n\n\n\n\nLimits\n\\[\n\\lim_{x \\to a} f(x) = L\n\\tag{10}\\]\nHow do we know if this limit exists?\nIf given \\(\\epsilon &gt; 0\\) we can find \\(\\delta &gt; 0\\) so that \\(0 &lt; |x - a| &lt; \\delta\\), this guarantees that \\(|f(x) - L| &lt; \\epsilon\\). Thus, \\(f\\) approaches \\(L\\) as \\(x\\) approaches \\(a\\) and we write Equation 10.\nThis definition of a limit is absolutely necessary for making calculus rigorous.\nSome Limit Theorems\nThe constant rule.\n\\[\n\\lim_{x \\to a} \\bigg[ c f(x) \\bigg] = c \\lim_{x \\to a} \\bigg[ f(x) \\bigg]\n\\]\nThe sum rule.\n\\[\n\\lim_{x\\to a} \\bigg[ f(x) + g(x) \\bigg] = \\lim_{x\\to a} \\bigg[ f(x) \\bigg] + \\lim_{x\\to a} \\bigg[ g(x)\\bigg]\n\\]\nThe power rule.\n\\[\n\\lim_{x \\to a} x^n = a^n\n\\]"
  },
  {
    "objectID": "calculus-de.html#introduction",
    "href": "calculus-de.html#introduction",
    "title": "1  Differential Equations",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nWhat are they?\nODE and PDE\nWe tend to use differential equations when it’s easier to describe how things change over time than the value of things at specific times. In other words, we figure out functions based on information about their rate of changes. For example, in models of population growth we usually start with \\(dN/dt\\) and then work backwards to find \\(N(t)\\).\n\n1.1.1 Growth\nExponential and Logistic growth.\nIn a population with exponential growth, the rate of population increase (\\(dN/dt\\)) is proportional to the number of individuals at time \\(t\\). We call this proportionality constant \\(k\\).\n\\[\n\\frac{dN}{dt} = k N\n\\tag{1.1}\\]\nYou can also think of \\(k\\) as a sort of per capita growth rate, which becomes clear if we rearrange the terms such that\n\\[\nk = \\frac{dN/dt}{N}\n\\]\nWe can get the formula for \\(N(t)\\) by rearranging Equation 1.1 and then integrating on both sides.\n\\[\n\\begin{align}\n\\text{Step 1}: && \\int \\frac{1}{N}dN &= \\int kdt \\\\\\\\\n\\text{Step 2}: && \\log(|N|) + c_1 &= kt + c_2 \\\\\\\\\n\\text{Step 3}: && N &= e^{kt} C\n\\end{align}\n\\]\nHere, \\(C\\) is a constant that also happens to equal \\(N(t = 0)\\) or \\(N_0\\).\nThus, we get the following expression for exponential growth:\n\\[\nN_t = e^{kt}N_0\n\\tag{1.2}\\]\nIn a population with logistic growth, a population’s per capita growth rate gets smaller as population size approaches a maximum imposed by limited resources in the environment, known as the carrying capacity (\\(K\\)).\n\\[\n\\frac{dN}{dt} = k \\Bigg(\\frac{K-N}{K} \\Bigg) N\n\\]\nYou can think of \\(k\\) as the hypothetical growth rate at which the population would grow in the absence of the constraints imposed by the carrying capacity. In other words, when \\(N < K\\), the expression \\((K-N) / N\\) represents the fraction of the carrying capacity that has not yet been “used up.” Once \\(N = K\\) the population growth becomes zero.\nSolving this differential equation is less straightforward, but we can derive the following equation using similar methods:\n\\[\nN(t) = \\frac{N_0 K}{(K- N_0) e^{-kt} + N_0}\n\\tag{1.3}\\]"
  }
]